---
layout: default
nav_active: shared-tasks
title: Touché at CLEF 2026 - Causality Extraction
description: Causality lies at the heart of human reasoning. This shared task explores how causal claims and their counterclaims can be extracted from text.
---
<nav class="uk-container">
    <ul class="uk-breadcrumb">
        <li><a href="../../index.html">Touché</a></li>
        <li><a href="../../shared-tasks.html">Shared Tasks</a></li>
        <li class="uk-disabled"><a href="#">Causality Extraction 2026</a></li>
    </ul>
</nav>

<main class="uk-section uk-section-default">
<div class="uk-container">
<div class="uk-container uk-margin-small">
<h1 class="uk-margin-remove-top uk-margin-remove-bottom">Causality Extraction 2026</h1>
<ul class="uk-list">
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#synopsis">Synopsis</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#important_dates">Important Dates</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task">Task</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#data">Data</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#submission">Submission</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#evaluation">Evaluation</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-committee">Task Committee</a></li>
</ul>
</div>

<div class="uk-container uk-margin-medium">

<h2 id="synopsis">Synopsis</h2>
<ul>
<li>Sub-Task 1: Given a natural language text, classify whether it contains causal information or not.</li>
<li>Sub-Task 2: Given a natural language text, identify text spans that are good candidates to express events or concepts that are stated to partake in a causal relationship.</li>
<li>Sub-Task 3: Given a natural language text and a candidate pair of events or concepts, E<sub>1</sub> and E<sub>2</sub>, classify the type of causal relationship expressed between E<sub>1</sub> and E<sub>2</sub>.</li>
<li>Communication: [mailing lists: <a href="https://groups.google.com/g/touche-lab">participants</a>, <a href="mailto:touche@webis.de">organizers</a>] </li>
</ul>

<!--
<a class="uk-button uk-button-primary" href="https://clef2025-labs-registration.dei.unipd.it/">Register for participation</a>
-->
<a href="https://groups.google.com/g/touche-lab" class="uk-button uk-button-primary">Join the Touché mailing list</a>

<h2 id="important-dates" class="uk-margin-large-top">Important Dates</h2>
<p>See the <a href="https://clef2026.clef-initiative.eu/dates/#participating-in-a-lab">CLEF 2026 homepage</a>.</p>
<p>Subscribe to the <a href="https://groups.google.com/g/touche-lab">Touché mailing list</a> to receive notifications.</p>

<h2 id="task">Task</h2>
<p>Given a natural language sentence, the extraction of causal statements, causality extraction, can be split into three steps; each of which is its own sub-task:
<ol>
<li>Classify for the entire sentence if contains causal information or not.</li>
<li>Identify text-spans that are good candidates to partake in a claimed or refuted causal relationship.</li>
<li>Given a pair of candidates, classify whether the sentence supports (procausal) or refutes (concausal) a causal relationship, or makes no statement how the pair relates (uncausal).</li>
</ol>
</p>
<p>Participants can choose to participate in one, two, or all three Sub-Tasks.</p>

<h2 id="data">Data</h2>
<p>The dataset for all three of the Sub-Tasks will be published at a later date. For now, a <a href="https://zenodo.org/records/17776007">dummy dataset</a> is provided that uses the same format as the dataset. Participants can use the published splits to train and validate their submission. For evaluation, we will use a separate, unpublished test split with the same format.</p>

<details>
<summary>Data format (click to see)</summary>
The dataset follows the <a href="https://huggingface.co/docs/hub/datasets-cards">Dataset Card Specification</a> which configures the file structure and tasks for each subtask and split. To open the dataset, it should be downloaded and unpacked from Zenodo. Then, <a href="https://huggingface.co/docs/datasets/">HF Datasets</a> can be used to open the dataset. The following Python code opens the dataset and prints the first entry in the training set for each subtask (<code>causality detection</code>, <code>causal candidate extraction</code>, and <code>causality identification</code>) to the console. 
<pre><code>from pathlib import Path
from datasets import load_dataset

path_to_dataset = Path(".")  # Replace me with the actual path!

dataset = load_dataset(str(path_to_dataset.absolute()), "causality detection")
print("Causality Detection")
print("Splits:", list(dataset.keys()))
print("Example:", dataset["train"][0])
print()

dataset = load_dataset(str(path_to_dataset.absolute()), "causal candidate extraction")
print("Causal Candidate Extraction")
print("Splits:", list(dataset.keys()))
print("Example:", dataset["train"][0])
print()

dataset = load_dataset(str(path_to_dataset.absolute()), "causality identification")
print("Causality Identification")
print("Splits:", list(dataset.keys()))
print("Example:", dataset["train"][0])
print()
</code></pre>
</details>

<h2 id="submission">Submission</h2>
<p>We ask participants to use <a href="https://www.tira.io/">TIRA</a> for result submissions.<!-- In case of problems or questions concerning TIRA, please use the <a href="https://www.tira.io/c/touche/">TIRA forum</a>.--> Each team can submit <b>up to one</b> approach per Sub-Task.</p>

<h3>Submission for Sub-Task 1</h3>
<p>The submissions for Sub-Task 1 need to be made as a <b>code submission</b>.</p>
<p>The output of the code submission needs to be a JSONL file. Each line in the JSONL file should be in the following JSON format:</p>
<ul>
<li><code>id</code>: The ID of the text that was classified.</li>
<li><code>label</code>: The label assigned by your classifier. <code>1</code> if the response contains (pro-/con-)causal information and <code>0</code> otherwise.</li>
<li><code>tag</code>: A tag that identifies your group and the method you used to produce the run.</li>
</ul>
<details>
<summary>Example submission file (click to see)</summary>
<pre><code>{
    'id': 'cnc_train_01_0_234_0', 
    'label': 1, 
    'tag': 'myGroupMyMethod'
}</code></pre>
</details>

<h3>Submission for Sub-Task 2</h3>
<p>The submissions for Sub-Task 2 need to be made as a <b>code submission</b>.</p>
<p>The output of the code submission needs to be a JSONL file. Each line in the JSONL file should be in the following JSON format:</p>
<ul>
<li><code>id</code>: The ID of the text that was classified.</li>
<li><code>spans</code>: The list of spans your submission predicted to partake in a causal relationship according to the input text. A span is a pair of two positive integers that give the start and end index in characrers.</li>
<li><code>tag</code>: A tag that identifies your group and the method you used to produce the run.</li>
</ul>
<details>
<summary>Example submission file (click to see)</summary>
<pre><code>{
    'id': 'cnc_train_01_0_234_0', 
    'label': [[0, 10], [20, 25]], 
    'tag': 'myGroupMyMethod'
}</code></pre>
</details>

<h3>Submission for Sub-Task 3</h3>
<p>The submissions for Sub-Task 3 need to be made as a <b>code submission</b>.</p>
<p>The output of the code submission needs to be a JSONL file. Each line in the JSONL file should be in the following JSON format:</p>
<ul>
<li><code>id</code>: The ID of the text that was classified.</li>
<li><code>label</code>: The label assigned by your classifier. <code>0</code> if the marked spans (ARG0 and ARG1) are uncausal (nothing can be said about how ARG0 causally influences ARG1), <code>1</code> if they are pro-causal (ARG0 causes ARG1) and <code>2</code> if they are con-causal (ARG0 does not cause ARG1).</li>
<li><code>tag</code>: A tag that identifies your group and the method you used to produce the run.</li>
</ul>
<details>
<summary>Example submission file (click to see)</summary>
<pre><code>{
    'id': 'cnc_train_01_0_234_0_1', 
    'label': 1,
    'tag': 'myGroupMyMethod'
}</code></pre>
</details>

<h2 id="evaluation">Evaluation</h2>

<h3>Evaluation for Sub-Task 1</h3>
<p>Sub-Task 1 is evaluated as a binary classification task using the F<sub>1</sub>-score.</p>

<h3>Evaluation for Sub-Task 2</h3>
<p>Sub-Task 2 is evaluated as a token classification problem with BIO-tags using the F<sub>1</sub>-score.</p>

<h3>Evaluation for Sub-Task 3</h3>
<p>Sub-Task 3 is evaluated as a ternary classification task using the F<sub>1</sub>-score.</p>

<h2 id="task-committee">Task Committee</h2>
<div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
{% include people-cards/hagen-tim.html gender="male" %}
{% include people-cards/potthast.html gender="male" %}
</div>
<div class="uk-container uk-padding-large uk-padding-remove-bottom">
{% include organizations/clef-organizations-section.html year=2026 %}
</div>
</div>
</div>
</main>