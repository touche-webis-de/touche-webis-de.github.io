---
layout: default
nav_active: shared-tasks
title: TouchÃ© at CLEF 2026 - Generalizability of Argument Identification in Context
description: ðŸ‘‰ To be an argument or not to be an argument â€” that is the question that current models cannot answer and is raised by this task @ CLEF 2026 ðŸ¤ž
---
<script>
  window.MathJax = {
    tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<nav class="uk-container">
    <ul class="uk-breadcrumb">
        <li><a href="../../index.html">TouchÃ©</a></li>
        <li><a href="../../shared-tasks.html">Shared Tasks</a></li>
        <li class="uk-disabled"><a href="#">Generalizability of Argument Identification in Context 2026</a></li>
    </ul>
</nav>

<main class="uk-section uk-section-default">
<div class="uk-container">
<div class="uk-container uk-margin-small">
<h1 class="uk-margin-remove-top uk-margin-remove-bottom">Generalizability of Argument Identification in Context 2026</h1>
<ul class="uk-list">
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#synopsis">Synopsis</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#important_dates">Important Dates</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task">Task</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#data">Data</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#evaluation">Evaluation</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#submission">Submission</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#related-work">Related Work</a></li>
<li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-committee">Task Committee</a></li>
</ul>
</div>

<div class="uk-container uk-margin-medium">

<h2 id="synopsis">Synopsis</h2>
<ul>
<li>Task: Decide if a sentence, in its context, constitutes an argument or not.</li>
<li>Communication: [mailing lists: <a href="https://groups.google.com/g/touche-lab">participants</a>, <a href="mailto:touche@webis.de">organizers</a>] </li>
</ul>

<a class="uk-button uk-button-primary" href="https://clef-labs-registration.dipintra.it/">Register for participation</a>
<a href="https://groups.google.com/g/touche-lab" class="uk-button uk-button-primary">Join the TouchÃ© mailing list</a>

<h2 id="important-dates" class="uk-margin-large-top">Important Dates</h2>
<p>See the <a href="https://clef2026.clef-initiative.eu/dates/#participating-in-a-lab">CLEF 2026 homepage</a>.</p>
<p>Subscribe to the <a href="https://groups.google.com/g/touche-lab">TouchÃ© mailing list</a> to receive notifications.</p>


<h2 id="task">Task</h2>
<p>Given a sentence from a dataset along with metadata about its provenance, such as the source text and the dataset's annotation guidelines, predict whether the sentence can be annotated as an argument or not. In particular, participants are encouraged to develop robust systems that generalize beyond lexical shortcuts to unseen datasets and investigate ways to exploit rich context information for this purpose.</p>



<h2 id="data">Data</h2>
<p>For the task, training data will be provided as a subset of the 17 benchmark datasets totaling about 345k labeled sentences and identified as most relevant for argument identification in <a href="https://aclanthology.org/2025.acl-long.1164/">this paper</a>.
This subset includes sentences each labeled as <i>argument</i> or <i>no-argument</i>, according to the respective dataset annotations, along with accompanying metadata such as IDs, generated training and development splits, links to original data sources and annotation guidelines, as well as the scripts used for data preparation.</p>

<h2 id="evaluation">Evaluation</h2>
<p>The systems will be evaluated on test data that differs from the development data. This includes partially or fully held-out portions of the datasets used for sampling, as well as newly created data reflecting diverse domains and annotation guidelines. This setup addresses the risk of data contamination in LLMs and for participantsâ€™ potential use of additional datasets during training.

Generalizability will be measured using the macro F$_1$-score. To evaluate the systems, the macro F$_1$-score will be specified for each test dataset, along with the overall average of all these values.</p>

<h2 id="submission">Submission</h2>
<p>We ask participants to use <a href="https://www.tira.io/">TIRA</a> for submissions. Each team can submit <b>up to 3</b> approaches to the task.</p>
<p>The submissions for this task must be made as a <b>run submission</b>, meaning the test data will be provided in the same format as the training and development data, and participants must return their predictions.

<h3 id="output">Output Format</h3>
<p>The output of the submission needs to be a <b>JSONL</b> file. Each line in the file must be in the following <b>JSON</b> format:
<ul>
<li><code>id</code>: The ID of the sentence that was classified.</li>
<li><code>label</code>: The label assigned by your classifier. <code>Argument</code> if the sentence is an argument and <code>No-Argument</code> otherwise.</li>
</ul>
<details>
<summary>Example JSONL file (click to see)</summary>
<pre><code>
    {
        "id": "SCIARK-test-21",
        "label": "Argument"
    }
    {
        "id": "USELEC-test-171",
        "label": "No-Argument"
    }
</code></pre>
</details>
<h3 id="input">Input Format</h3>
<p>The input for the submission will also be provided as a <b>JSONL</b> file, where each line follows the <b>JSON</b> structure below:</p>
<ul>
  <li><code>id</code>: A unique sentence identifier composed of a dataset prefix, the split name, and a running number (e.g., <code>ABSTRCT-train-1</code>).</li>
  <li><code>paper</code>: A link to the corresponding dataset paper.</li>
  <li><code>document</code>: A link to the source document from which the sentence was extracted.</li>
  <li><code>guidelines</code>: A link to the annotation guidelines used to label the sentence.</li>
  <li><code>label</code>: The gold label, where <code>Argument</code> indicates an argument sentence and <code>No-Argument</code> otherwise.</li>
  <li><code>sentence</code>: The sentence itself.</li>
</ul>

<details>
<summary>Example JSONL file (click to see)</summary>
<pre><code>
    {
        "id": "ABSTRCT-train-403",
        "paper": "https://raw.githubusercontent.com/TomatenMarc/GAIC-2026/refs/heads/main/datasets/ABSTRCT/paper/ABSTRCT.pdf",
        "document": "https://raw.githubusercontent.com/TomatenMarc/GAIC-2026/refs/heads/main/datasets/ABSTRCT/data/ABSTRCT-19.txt",
        "guidelines": "https://raw.githubusercontent.com/TomatenMarc/GAIC-2026/refs/heads/main/datasets/ABSTRCT/guidelines/ABSTRCT-Guidelines.pdf",
        "label": "Argument",
        "sentence": "Therefore, single-fraction radiotherapy should be considered as the palliative treatment of choice for cancer patients with painful bone metastases."
    }
    {
        "id": "FINARG-dev-262",
        "paper": https://raw.githubusercontent.com/TomatenMarc/GAIC-2026/refs/heads/main/datasets/FINARG/paper/FINARG.pdf,
        "document": "https://raw.githubusercontent.com/TomatenMarc/GAIC-2026/refs/heads/main/datasets/FINARG/data/FINARG-631.txt",
        "guidelines": "-",
        "label": "No-Argument",
        "sentence": "I can take the first one, Brian, on the time spent metric."
    }
</code></pre>
</details>

<h4 id="Please Note">Please Note</h4>
<ul>
  <li>Links provided under <code>paper</code> and <code>guidelines</code> point to a <b>PDF</b> file.</li>
  <li>Links provided under <code>document</code> point to a <b>TXT</b> file.</li>
  <li>Context materials (e.g., documents) are currently hosted on <a href="https://github.com/TomatenMarc/GAIC-2026">GitHub</a> for example purposes (WIP; example links are stable).</li>
  <li>The final data will be provided via <a href="https://www.tira.io/">TIRA</a> in a folder structure mirroring the repository layout (e.g., <code>./datasets/ABSTRCT/data/ABSTRCT-19.txt</code>).</li>
  <li>Individual files for the train, dev, and test splits will also be provided via <a href="https://www.tira.io/">TIRA</a>.</li>
</ul>

<h2><a id="related-work"></a>Related Work</h2>
<ul>
<li>Marc Feger, Katarina Boland, and Stefan Dietze. <a href="https://aclanthology.org/2025.acl-long.1164/"> Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments.</a> In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, July 2025.</li>
<li>Terne Sasha Thorn Jakobsen, Maria Barrett, and Anders SÃ¸gaard. <a href="https://aclanthology.org/2021.starsem-1.25/">Spurious Correlations in Cross-Topic Argument Mining</a>. In Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics, August 2021.</li>
<li>Robert Geirhos, JÃ¶rn-Henrik Jacobsen, Claudio Michaelis, Robert Zemel, Wieland Brendel, Matthias Bethge & Felix A. Wichmann. <a href="https://doi.org/10.1038/s42256-020-00257-z">Shortcut learning in deep neural networks</a>. Nature Machine Intelligence, November 2020.</li>
</ul>

<h2 id="task-committee">Task Committee</h2>
<div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
{% include people-cards/feger.html gender="male" %}
{% include people-cards/boland.html gender="female" %}
{% include people-cards/romberg.html gender="female" %}
{% include people-cards/dietze.html gender="male" %}
</div>
<div class="uk-container uk-padding-large uk-padding-remove-bottom">
{% include organizations/clef-organizations-section.html year=2026 %}
</div>
</div>
</div>
</main>